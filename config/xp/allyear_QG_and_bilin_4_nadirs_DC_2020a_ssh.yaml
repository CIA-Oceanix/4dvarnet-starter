# @package _global_

paths:
    natl_gf_5nads: /DATASET/NATL/cal_data_new_errs.nc
    enatl_gf_5nads: ../sla-data-registry/qdata/enatl_wo_tide.nc

domain: ???

trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: False
  gradient_clip_val: 0.5
  accelerator: gpu
  devices: 1
  logger: 
    _target_: pytorch_lightning.loggers.CSVLogger
    save_dir: ${hydra:runtime.output_dir}
    name: ${hydra:runtime.choices.xp}
    version: ''
  max_epochs: 100 #150
  callbacks:
    - _target_: src.versioning_cb.VersioningCallback
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_mse
      save_top_k: 3
      filename: '{val_mse:.5f}-{epoch:03d}'

datamodule:
  _target_: src.data.BaseDataModule
  input_da: 
    #_target_: src.utils.load_altimetry_data
    path: ${paths.natl_gf_5nads}
    _target_: src.utils.load_full_natl_data
    path_obs: "/DATASET/NATL/cal_data_new_errs.nc"
    path_gt: "/DATASET/NATL/NATL60-CJM165_NATL_ssh_y2013.1y.nc"
    obs_var: four_nadirs
    obs_gt: ssh
  domains:
    # train:
    #   time: {_target_: builtins.slice, _args_: ['2012-11-01', '2012-11-15']}  #['2012-10-01', '2012-10-15']} 
    # val: 
    #   time: {_target_: builtins.slice, _args_: ['2012-11-01', '2012-11-15']}
    # test: 
    #   time: {_target_: builtins.slice,  _args_: ['2012-11-01', '2012-11-15']}
    train:
      time: {_target_: builtins.slice, _args_: ['2013-02-24', '2013-09-30']}
    val: 
      time: {_target_: builtins.slice, _args_: ['2013-01-02', '2013-02-24']}
    test: 
      time: {_target_: builtins.slice,  _args_: ['2012-10-01', '2012-12-15']}
  xrds_kw:
    patch_dims: { time: 15, lat: 240, lon: 240}
    strides: { time: 1, lat: 200, lon: 200}
    domain_limits: ${domain.train}
  dl_kw: {batch_size: 1, num_workers: 1}
  aug_kw:
    aug_factor: 1
    aug_only: True

model:
  _target_: src.models.Lit4dVarNet
  persist_rw: False
  opt_fn:
    _target_: src.utils.cosanneal_lr_adam_QG
    _partial_: true
    lr: 1e-3
    T_max: ${trainer.max_epochs}
  rec_weight:
      _target_: src.utils.get_triang_time_wei
      patch_dims: ${datamodule.xrds_kw.patch_dims}
      crop: {time: 0, lat: 0, lon: 20}
      offset: 1
  solver: 
    _target_: src.models.GradSolver_QG
    x_init: datamodule.input_da.path_mdt
    n_step: 20 #20 #5 #5 #10
    lr_mod: 0.1 # 0.1
    lr_grad: 100 #1000 # 1e3 #1e3
    save_debugg_path : '/homes/g24meda/lab/4dvarnet-starter/outputs/QG_and_bilin_15days_lrgmod_01_lrgrad_100_nstep_20_sigma2_kernelsize21_alpha1_1_alpha2_05_avgpool2_dt15min_dimhidd48_nonormalization/'
    prior_cost: 
      _target_: src.models.QGCost_and_bilin 
      # bilin cost parameters
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 32 #32
      bilin_quad: False
      downsamp: 2
      # Qg cost parameters
      domain_limits: ${domain.train} # limits in lon, lat (degrees)
      res: 0.05 # resolution (degrees)
      avg_pool : 2 #2 #None
      dt: 900 #600 # 120 #300 # Integration time step (sec) : 3 minutes
      tint: 86400 # Integration time (sec) : 1 day
      SSH:  # Mask for SSH
      c: 2.7 # phase velocity (m/s)
      g: 9.81 # m/s^2
      f: # Coriolis freq, if not provided computed from c and g 
      Kdiffus: # diffusion coefficient
      device: 'cuda'
      save_debugg_path : ${model.solver.save_debugg_path}
    obs_cost: 
      _target_: src.models.BaseObsCost
    grad_mod: 
      _target_: src.models.ConvLstmGradModel
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 48 #48 #96 #24 #48
  test_metrics: ${metrics.test_metrics}
  pre_metric_fn: 
        _target_: xarray.Dataset.sel
        _partial_: True
        time: {_target_: builtins.slice, _args_: ["2012-10-22", "2012-12-02"]}
        lat: ${domain.test.lat}
        lon: ${domain.test.lon}

metrics:
  nrmse_scores: {_target_: src.utils.rmse_based_scores_from_ds, _partial_: True}
  psd_scores: {_target_: src.utils.psd_based_scores_from_ds, _partial_: True}
  get0: {_target_: operator.itemgetter, _args_: [0]}
  get1: {_target_: operator.itemgetter, _args_: [1]}
  test_metrics:
    'mu': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.nrmse_scores}', '${metrics.get0}']}
    'sig': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.nrmse_scores}', '${metrics.get1}']}
    'lx': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.psd_scores}', '${metrics.get0}']}
    'lt': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.psd_scores}', '${metrics.get1}']}

entrypoints:
  - _target_: pytorch_lightning.seed_everything
    seed: 333
  - _target_: src.train.base_training
    trainer: ${trainer}
    lit_mod: ${model}
    dm: ${datamodule}

defaults:
  - /domain: gf_bis
  - _self_

