# @package _global_

resolution: '1_20'
entrypoint: train  # 'train' or 'test'
# checkpoint: outputs/2023-11-28/11-46-24/comfra/checkpoints/val_mse=7.97592-epoch=434.ckpt
#checkpoint: outputs/val_rmse_0.0135_epoch_299.ckpt

val_period:
  time:
    _target_: builtins.slice
    _args_:
      - 2009-07-01
      - 2009-08-11

paths:
    enatl_train: '/DATASET/eNATL/eNATL60_BLB002_cutoff_freq_0_1000m_regrid.nc'
    natl_test: '/DATASET/eNATL/NATL60GULF-CJM165_cutoff_freq_0_1000m_regrid.nc'
    inp:
      train: '/DATASET/eNATL/eNATL60_BLB002_cutoff_freq_0_1000m_regrid.nc'
      test: '/DATASET/eNATL/NATL60GULF-CJM165_cutoff_freq_0_1000m_regrid.nc'
    tgt:
      train: '/DATASET/eNATL/eNATL60_BLB002_cutoff_freq_0_1000m_regrid.nc'
      test: '/DATASET/eNATL/NATL60GULF-CJM165_cutoff_freq_0_1000m_regrid.nc'
  # inp:
  #   train: /DATASET/eNATL/eNATL60_BLB002_SSH_nadirs/eNATL60-BLB002-7nadirs-2009-2010-${resolution}.nc
  #   test: /DATASET/NATL/NATL60-CJM165-7nadirs-2012-2013-${resolution}.nc
  # tgt:
  #   train: /DATASET/eNATL/eNATL60_BLB002_SSH_nadirs/eNATL60-BLB002-ssh-2009-2010-${resolution}.nc
  #   test: /DATASET/NATL/NATL60-CJM165-ssh-2012-2013-${resolution}.nc

trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: false
  gradient_clip_val: 0.5
  accelerator: gpu
  devices: 1
  logger:
    _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    save_dir: ${hydra:runtime.output_dir}
    name: ${hydra:runtime.choices.xp}
    version: ''
  max_epochs: 10
  callbacks:
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_mse
      save_top_k: 3
      filename: '{val_mse:.5f}-{epoch:03d}'

datamodule:
  _target_: src.data.BaseDataModule
  input_da:
    _target_: src.utils.load_natl_data
    tgt_path: ${paths.tgt[${entrypoint}]}  # .train or .test
    inp_path: ${paths.inp[${entrypoint}]}  # .train or .test
    tgt_var: ecs
    inp_var: ecs
    domain: ${domain.train}
    period: ${period[${entrypoint}]}  # .train or .test
  domains:
    train: ${period.train}
    val: ${val_period}
    test:
      time: {_target_: builtins.slice,  _args_: ['2012-10-01', '2012-12-20']}  # ${period.test}
  xrds_kw:
    patch_dims: { time: 15, lat: 240, lon: 240}
    strides: { time: 1, lat: 200, lon: 200}
    domain_limits: ${domain.train}
  dl_kw: {batch_size: 4, num_workers: 1}
  aug_kw:
    aug_factor: 2
    aug_only: true

model:
  _target_: src.models.Lit4dVarNet
  persist_rw: false
  opt_fn:
    _target_: src.utils.cosanneal_lr_adam
    _partial_: true
    lr: 1e-3
    T_max: ${trainer.max_epochs}
  rec_weight:
      _target_: src.utils.get_triang_time_wei
      patch_dims: ${datamodule.xrds_kw.patch_dims}
      crop: {time: 0, lat: 20, lon: 20}
      offset: 1
  solver:
    _target_: src.models.GradSolver
    n_step: 10
    lr_grad: 1e3
    prior_cost:
      _target_: src.models.BilinAEPriorCost
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 32
      bilin_quad: false
      downsamp: 2
    obs_cost:
      _target_: src.models.BaseObsCost
    grad_mod:
      _target_: src.models.ConvLstmGradModel
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 48
  sampling_rate: 0.1
  test_metrics: ${metrics.test_metrics}
  pre_metric_fn:
    _target_: xarray.Dataset.sel
    _partial_: true
    time: {_target_: builtins.slice, _args_: ["2012-10-22", "2012-12-02"]}
    lat: ${domain.test.lat}
    lon: ${domain.test.lon}

metrics:
  nrmse_scores: {_target_: src.utils.rmse_based_scores_from_ds, _partial_: true}
  psd_scores: {_target_: src.utils.psd_based_scores_from_ds, _partial_: true}
  get0: {_target_: operator.itemgetter, _args_: [0]}
  get1: {_target_: operator.itemgetter, _args_: [1]}
  test_metrics:
    'μ': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.nrmse_scores}', '${metrics.get0}']}
    'σ': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.nrmse_scores}', '${metrics.get1}']}
    'λx': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.psd_scores}', '${metrics.get0}']}
    'λt': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.psd_scores}', '${metrics.get1}']}

entrypoints:
  - _target_: pytorch_lightning.seed_everything
    seed: 333
  - _target_: src.train.base_training
    trainer: ${trainer}
    lit_mod: ${model}
    dm: ${datamodule}
    #ckpt: ${checkpoint}

defaults:
  - /domain: gf
  - /period: allyear
  # - /period@val_period: midsummer
  - _self_