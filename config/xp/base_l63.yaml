# @package _global_

xp_name: baseline


datamodule:
  _target_: src.data_l63.BaseDataModule
  param_datamodule:
    dl_kw: {batch_size: 128, num_workers: 1}
  input_data:
    _target_: src.data_l63.create_l63_datasets
    param_dataset:
      path_l63_dataset: '../../Dataset4DVarNet/dataset_L63_with_noise.nc'
      genSuffixObs: 'JamesData'
      flag_load_all_data: False
      flag_generate_L63_data: False
      NbTraining: 10000
      NbTest: 200
      time_step: 1
      dT: 200
      varNoise: 2.0
      sampling_step: ??
      flagTypeMissData: 2
      
model:
  _target_: src.models_l63.Lit4dVarNet_L63
  params:
    k_n_grad: 2
    n_grad: 5
    lr: 1e-3 
    batch_size: 128
    DimAE: 10
    phi_param: 'unet'
    solver: ?? #'4dvarnet-with-subgradients' #'4dvarnet-with-rnd-grad' #'4dvarnet-with-rnd' #'4dvarnet-with-state-and-rnd' #'4dvarnet-with-state-and-rnd' #
    dim_grad_solver: 100 #25
    dropout: 0.2
    alpha_prior: 0.1
    alpha_mse: 1.
    alpha_var_cost_grad: 0.1
    lr_grad: 0.
    lr_rnd: 0.e-3
    sig_rnd_init: 0e-2
    sig_lstm_init: 0e-2
    suffix_exp: '-new'
    UsePeriodicBoundary: False
    degradation_operator: 'no-degradation' #'median-degradation' #
    sig_perturbation_grad: 1e-2
    shapeData:
      - 3
      - ${datamodule.input_data.param_dataset.dT}
      - 1
  patch_weight:
    _target_: src.models_l63.get_constant_crop_l63
    patch_dims: ${model.params.shapeData}
    crop: 
      - 0
      - 0
      - 0

trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: False
  #gradient_clip_val: 0.5
  accelerator: gpu
  devices: 1
  logger: 
    _target_: pytorch_lightning.loggers.CSVLogger
    save_dir: ${hydra:runtime.output_dir}
    name: ${hydra:runtime.choices.xp}
    version: ''
  max_epochs: 400
  callbacks:
    - _target_: src.versioning_cb.VersioningCallback
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_mse
      save_top_k: 3
      filename: 
        _target_: src.models_l63.create_filename_ckpt
        suffix: '{val_mse:.4f}-{epoch:03d}'
        params_data: ${datamodule.input_data.param_dataset}
        params_model: ${model.params}
        
entrypoints:
  - _target_: pytorch_lightning.seed_everything
    seed: 333
  - _target_: src.train.base_training 
    trainer: ${trainer}
    lit_mod: ${model}
    dm: ${datamodule}
#    ckpt: 'outputs/2023-05-07/22-59-30/base_l63/checkpoints/val_mse=0.6534-epoch=379.ckpt'
#  - _target_: src.test.base_testing #
#    trainer: ${trainer}
#    lit_mod: ${model}
#    dm: ${datamodule}
#    ckpt: 'outputs/2023-05-09/12-22-22/base_l63/checkpoints/val_mse=0.0106-epoch=005.ckpt'
#    test_fn:
#      _target_: src.utils.diagnostics
#      _partial_: true
#      test_domain:
#        time: {_target_: builtins.slice, _args_: ["2012-10-22", "2012-12-02"]}
#        lat: ${domain.test.lat}
#        lon: ${domain.test.lat}
  