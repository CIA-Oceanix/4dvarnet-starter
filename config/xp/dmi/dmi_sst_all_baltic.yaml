# @package _global_

paths:
    #src: /gpfsstore/rech/yrf/uba22to/DMI
    src: /DATASET/mbeauchamp/DMI
    obs: ${paths.src}/training_dataset/DMI-L3S_GHRSST-SSTsubskin-night_SST_UHR_NRT-NSEABALTIC.nc
    #tgt: ${paths.src}/training_dataset/DMI-L3S_GHRSST-SSTsubskin-night_SST_UHR_NRT-NSEABALTIC.nc
    tgt: ${paths.src}/training_dataset/DMI-L4_GHRSST-SSTfnd-DMI_OI-NSEABALTIC.nc
    oi: ${paths.src}/training_dataset/DMI-L4_GHRSST-SSTfnd-DMI_OI-NSEABALTIC.nc

domain: ???

trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: False
  gradient_clip_val: 0.5
  accelerator: gpu
  devices: 1
  limit_train_batches: 300.
  limit_val_batches: 20.
  limit_test_batches: 200.
  accumulate_grad_batches: 16
  precision: 16
  logger: 
    _target_: pytorch_lightning.loggers.CSVLogger
    save_dir: ${hydra:runtime.output_dir}
    name: ${hydra:runtime.choices.xp}
    version: ''
  max_epochs: 150
  callbacks:
    #- _target_: src.versioning_cb.VersioningCallback
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_mse
      save_top_k: 3
      filename: '{val_mse:.5f}-{epoch:03d}'

datamodule:
  _target_: contrib.dmi.data.BaseDataModule
  input_da: 
    _target_: contrib.dmi.load_data.load_data
    path_obs: ${paths.obs}
    path_tgt: ${paths.tgt}
    #path_tgt: ${paths.oi}   
  domains:
    train:
      time: {_target_: builtins.slice, _args_: ['2019-05-01', '2020-12-31']}
    val:
      time: 
        - {_target_: builtins.slice, _args_: ['2021-01-01', '2021-01-31']}
        - {_target_: builtins.slice, _args_: ['2021-04-01', '2021-04-30']} 
        - {_target_: builtins.slice, _args_: ['2021-07-01', '2021-07-31']}
        - {_target_: builtins.slice, _args_: ['2021-10-01', '2021-10-31']}
    test:
      time: {_target_: builtins.slice, _args_: ['2021-06-01', '2021-06-30']}
    #train
    #  time: {_target_: builtins.slice, _args_: ['2021-01-01', '2021-01-31']}
    #val:
    #  time: {_target_: builtins.slice, _args_: ['2021-01-01', '2021-01-31']}
    #test:
    #  time: {_target_: builtins.slice, _args_: ['2021-01-01', '2021-01-21']}
  xrds_kw:
    patch_dims: { time: 7, lat: 600, lon: 600}
    strides: { time: 1, lat: 50, lon: 50}
    strides_test: {time: 1, lat: 500, lon: 500}
    domain_limits: ${domain.train}
  dl_kw: {batch_size: 2, num_workers: 0}
  #aug_kw:
  #  aug_factor: 1
  #  aug_only: True
  res: 0.02
  pads: 
    - False
    - False
    - True
  norm_stats:
    - 283.8052
    - 4.2381434

model:
  _target_: src.models.Lit4dVarNet_SST
  persist_rw: False
  opt_fn:
    _target_: src.utils.cosanneal_lr_adam
    _partial_: true
    lr: 1e-3
    T_max: ${trainer.max_epochs}
  rec_weight:
      _target_: src.utils.get_last_time_wei
      patch_dims: ${datamodule.xrds_kw.patch_dims}
      #crop: {time: 0, lat: 20, lon: 20}
      crop: {time: 0, lat: 50, lon: 50}
      offset: 1
  optim_weight:
      _target_: src.utils.get_linear_time_wei
      patch_dims: ${datamodule.xrds_kw.patch_dims}
      crop: {time: 0, lat: 50, lon: 50}
      offset: 1
  solver: 
    _target_: src.models.GradSolver
    n_step: 10
    lr_grad: 1e3
    # lr_grad: 0.2
    prior_cost: 
      _target_: src.models.BilinAEPriorCost
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 32
      bilin_quad: False
      # bilin_quad: True
      # downsamp: 2
    obs_cost: 
      _target_: src.models.BaseObsCost
    grad_mod: 
      _target_: src.models.ConvLstmGradModel
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 64
  test_metrics: ${metrics.test_metrics}
  pre_metric_fn: 
        _target_: xarray.Dataset.sel
        _partial_: True
        time: {_target_: builtins.slice, _args_: ["2021-01-01", "2021-12-31"]}
        lat: ${domain.test.lat}
        lon: ${domain.test.lon}
  path_mask: ${paths.oi}
  domain_limits: ${domain.train}
metrics:
  nrmse_scores: {_target_: src.utils.rmse_based_scores_from_ds, _partial_: True}
  psd_scores: {_target_: src.utils.psd_based_scores_from_ds, _partial_: True}
  get0: {_target_: operator.itemgetter, _args_: [0]}
  get1: {_target_: operator.itemgetter, _args_: [1]}
  test_metrics:
    'mu': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.nrmse_scores}', '${metrics.get0}']}
    'sig': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.nrmse_scores}', '${metrics.get1}']}
    'lx': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.psd_scores}', '${metrics.get0}']}
    'lt': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.psd_scores}', '${metrics.get1}']}

entrypoints:
  #- _target_: pytorch_lightning.seed_everything
  #  seed: 333
  - _target_: src.train.base_training
    trainer: ${trainer}
    lit_mod: ${model}
    dm: ${datamodule}

defaults:
  - /domain: baltic
  - _self_

