# @package _global_

paths:
    natl_gf_5nads: data/natl_gf_w_5nadirs.nc
    enatl_gf_5nads: data/enatl_wo_tide.nc
    masks_path: /DATASET/GLORYS12/global_obs_6sats_masks_2022.pickle
    glorys12_data: /DATASET/GLORYS12/reanalysis/glorys12_2020_4th.nc

domain:
  train:
    lat:
      _target_: builtins.slice
      _args_:
      - -80
      - 90
    lon:
      _target_: builtins.slice
      _args_:
      - -180
      - 180
  test:
    lat:
      _target_: builtins.slice
      _args_:
      - -79
      - 89
    lon:
      _target_: builtins.slice
      _args_:
      - -179
      - 179

trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: False
  gradient_clip_val: 0.5
  accelerator: gpu
  devices: 1
  logger:
    _target_: pytorch_lightning.loggers.CSVLogger
    save_dir: ${hydra:runtime.output_dir}
    name: ${hydra:runtime.choices.xp}
    version: ''
  max_epochs: 350
  limit_train_batches: 102
  callbacks:
    - _target_: src.versioning_cb.VersioningCallback
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_mse
      save_top_k: 3
      filename: '{val_mse:.5f}-{epoch:03d}'

datamodule:
  _target_: src.data.BaseDataModule
  input_da: 
    _target_: src.utils.open_glorys12_data
    path: ${paths.glorys12_data}
    masks_path: ${paths.masks_path}
    domain: ${domain.train}
  domains:
    train:
      time: {_target_: builtins.slice, _args_: ['2020-01-01', '2020-10-17']}
    val: 
      time: {_target_: builtins.slice, _args_: ['2020-10-18', '2020-11-24']}
    test: 
      time: {_target_: builtins.slice,  _args_: ['2020-11-25', '2020-12-31']}
  xrds_kw:
    patch_dims: { time: 29, lat: 48, lon: 48}
    strides: { time: 1, lat: 40, lon: 40}
    domain_limits: ${domain.train}
  dl_kw: {batch_size: 64, num_workers: 32}
  aug_kw:
    aug_factor: 2
    aug_only: True
  rec_crop:: {time: 0, lat: 4, lon: 4}

model:
  _target_: src.models.Lit4dVarNetForecast
  persist_rw: False
  opt_fn:
    _target_: src.utils.cosanneal_lr_adam
    _partial_: true
    lr: 1e-3
    T_max: ${trainer.max_epochs}
  rec_weight:
    _target_: src.utils.get_forecast_wei
    patch_dims: ${datamodule.xrds_kw.patch_dims}
    crop: {time: 0, lat: 4, lon: 4}
  solver:
    _target_: src.models.GradSolverZero
    n_step: 10
    lr_grad: 1e3
    # lr_grad: 0.2
    prior_cost:
      _target_: src.models.BilinAEPriorCost
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 64
      bilin_quad: False
      # bilin_quad: True
      #downsamp: 2
    obs_cost:
      _target_: src.models.BaseObsCost
    grad_mod:
      _target_: src.models.ConvLstmGradModel
      dim_in: ${datamodule.xrds_kw.patch_dims.time}
      dim_hidden: 96
  test_metrics: ${metrics.test_metrics}
  pre_metric_fn:
        _target_: xarray.Dataset.sel
        _partial_: True
        time: {_target_: builtins.slice, _args_: ["2020-11-26", "2020-12-29"]}
        lat: ${domain.test.lat}
        lon: ${domain.test.lon}

metrics:
  nrmse_scores: {_target_: src.utils.rmse_based_scores_from_ds, _partial_: True}
  psd_scores: {_target_: src.utils.psd_based_scores_from_ds, _partial_: True}
  get0: {_target_: operator.itemgetter, _args_: [0]}
  get1: {_target_: operator.itemgetter, _args_: [1]}
  test_metrics:
    'mu': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.nrmse_scores}', '${metrics.get0}']}
    'sig': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.nrmse_scores}', '${metrics.get1}']}
    'lx': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.psd_scores}', '${metrics.get0}']}
    'lt': {_target_: src.utils.pipe, _partial_: true, fns: ['${metrics.psd_scores}', '${metrics.get1}']}

entrypoints:
  - _target_: pytorch_lightning.seed_everything
    seed: 333
  - _target_: src.train.base_training
    trainer: ${trainer}
    lit_mod: ${model}
    dm: ${datamodule}

defaults:
  - _self_

